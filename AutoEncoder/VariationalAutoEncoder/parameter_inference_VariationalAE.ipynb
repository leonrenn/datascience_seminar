{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Inference of Gaussian Scaling Signal with AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external modules\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "# internal modules\n",
    "from dataset_VariationalAE import Dataset_1d\n",
    "from VariationalAE_model import VariationalAutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Net Structure and Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from training procedure\n",
    "\n",
    "# net parameters\n",
    "latent_dimension = 1\n",
    "variable_space = 20\n",
    "steps = 3 # not needed \n",
    "\n",
    "# model params\n",
    "size = 1000\n",
    "generations = 10000 # reduced in contrast to training\n",
    "batch_size = 64 # not needed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Train the Model with 1 Latent variable space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset_1d(variable_space=variable_space,\n",
    "                     size=size,\n",
    "                     generations=generations)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## MODEL ##########\n",
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=7, bias=True)\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Linear(in_features=7, out_features=1, bias=True)\n",
      "    (3): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=7, bias=True)\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Linear(in_features=7, out_features=20, bias=True)\n",
      "  )\n",
      "  (criterion): MSELoss()\n",
      ")\n",
      "########## MODEL ##########\n"
     ]
    }
   ],
   "source": [
    "model = VariationalAutoEncoder(latent_dimension=latent_dimension,\n",
    "                    variable_space=variable_space,\n",
    "                    steps=steps)\n",
    "\n",
    "# overview of the model structure\n",
    "print(\"########## MODEL ##########\")\n",
    "print(model)\n",
    "print(\"########## MODEL ##########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:307: LightningDeprecationWarning: The `LightningModule.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_<train/validation/test>_epoch_end` instead.\n",
      "  rank_zero_deprecation(\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | encoder   | Sequential | 157   \n",
      "1 | decoder   | Sequential | 175   \n",
      "2 | criterion | MSELoss    | 0     \n",
      "-----------------------------------------\n",
      "332       Trainable params\n",
      "0         Non-trainable params\n",
      "332       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "/opt/homebrew/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e73f0ef40e443491b898b55c090b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks = [TQDMProgressBar(refresh_rate=20)]\n",
    "trainer = Trainer(max_epochs=50, callbacks=callbacks)\n",
    "trainer.fit(model,dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
